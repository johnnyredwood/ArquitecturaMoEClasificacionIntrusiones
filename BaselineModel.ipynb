{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4c2903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in .\\.venv\\Lib\\site-packages (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in .\\.venv\\Lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=2.3.3 in .\\.venv\\Lib\\site-packages (from pandas) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\Lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in .\\.venv\\Lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in .\\.venv\\Lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in .\\.venv\\Lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in .\\.venv\\Lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in .\\.venv\\Lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in .\\.venv\\Lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in .\\.venv\\Lib\\site-packages (from matplotlib) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\.venv\\Lib\\site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in .\\.venv\\Lib\\site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in .\\.venv\\Lib\\site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in .\\.venv\\Lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\Lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in .\\.venv\\Lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in .\\.venv\\Lib\\site-packages (from seaborn) (2.4.1)\n",
      "Requirement already satisfied: pandas>=1.2 in .\\.venv\\Lib\\site-packages (from seaborn) (3.0.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in .\\.venv\\Lib\\site-packages (from seaborn) (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in .\\.venv\\Lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in .\\.venv\\Lib\\site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\Lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in .\\.venv\\Lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in .\\.venv\\Lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in .\\.venv\\Lib\\site-packages (from scikit-learn) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in .\\.venv\\Lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in .\\.venv\\Lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in .\\.venv\\Lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in .\\.venv\\Lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in .\\.venv\\Lib\\site-packages (from imbalanced-learn) (2.4.1)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in .\\.venv\\Lib\\site-packages (from imbalanced-learn) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in .\\.venv\\Lib\\site-packages (from imbalanced-learn) (1.8.0)\n",
      "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in .\\.venv\\Lib\\site-packages (from imbalanced-learn) (0.1.5)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in .\\.venv\\Lib\\site-packages (from imbalanced-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in .\\.venv\\Lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in .\\.venv\\Lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy<2.7,>=1.26.4 in .\\.venv\\Lib\\site-packages (from scipy) (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in .\\.venv\\Lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy in .\\.venv\\Lib\\site-packages (from xgboost) (2.4.1)\n",
      "Requirement already satisfied: scipy in .\\.venv\\Lib\\site-packages (from xgboost) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install pathlib\n",
    "%pip install scikit-learn\n",
    "%pip install imbalanced-learn\n",
    "%pip install scipy\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d152dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train=np.load(\"X_train.npy\")\n",
    "X_val=np.load(\"X_val.npy\")\n",
    "X_test=np.load(\"X_test.npy\")\n",
    "y_train=np.load(\"y_train.npy\")\n",
    "y_val=np.load(\"y_val.npy\")\n",
    "y_test=np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "class BusquedaHiperparametros:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.X_test = X_test\n",
    "        self.y_test= y_test\n",
    "\n",
    "        self.mejor_score = -1\n",
    "        self.mejor_modelo = None\n",
    "        self.mejores_parametros = None\n",
    "        self.nombre_modelo= None\n",
    "\n",
    "        clases_unicas = np.unique(y_train)\n",
    "\n",
    "        pesos = compute_class_weight(\n",
    "            class_weight=\"balanced\",\n",
    "            classes=clases_unicas,\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "        #Puedo implementar funciones custom class weight para no usar balanced???\n",
    "\n",
    "        self.class_weight = dict(zip(clases_unicas, pesos))\n",
    "\n",
    "        # Para XGBoost \n",
    "        self.sample_weight = np.array(\n",
    "            [self.class_weight[y] for y in y_train]\n",
    "        )\n",
    "\n",
    "    def crear_modelo(self, tipo_modelo, parametros):\n",
    "\n",
    "        if tipo_modelo == \"rf\":\n",
    "\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "            return RandomForestClassifier(\n",
    "                class_weight=self.class_weight,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                **parametros\n",
    "            )\n",
    "\n",
    "        elif tipo_modelo == \"svm\":\n",
    "\n",
    "            from sklearn.svm import SVC\n",
    "\n",
    "            return SVC(\n",
    "                class_weight=self.class_weight,\n",
    "                probability=True,\n",
    "                **parametros\n",
    "            )\n",
    "\n",
    "        elif tipo_modelo == \"xgb\":\n",
    "\n",
    "            from xgboost import XGBClassifier\n",
    "\n",
    "            return XGBClassifier(\n",
    "                eval_metric=\"mlogloss\",\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                **parametros\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Modelo no soportado\")\n",
    "\n",
    "\n",
    "    def obtener_grid(self, tipo_modelo):\n",
    "\n",
    "        if tipo_modelo == \"rf\":\n",
    "            return {\n",
    "                \"n_estimators\": [200, 400],\n",
    "                \"max_depth\": [None, 20],\n",
    "                \"min_samples_leaf\": [1, 4]\n",
    "            }\n",
    "\n",
    "        elif tipo_modelo == \"svm\":\n",
    "            return {\n",
    "                \"C\": [1, 10, 100],\n",
    "                \"gamma\": [\"scale\", 0.01],\n",
    "                \"kernel\": [\"rbf\"]\n",
    "            }\n",
    "\n",
    "        elif tipo_modelo == \"xgb\":\n",
    "            return {\n",
    "                \"n_estimators\": [300, 600],\n",
    "                \"max_depth\": [4, 6],\n",
    "                \"learning_rate\": [0.05, 0.1]\n",
    "            }\n",
    "\n",
    "    def buscar(self, tipo_modelo):\n",
    "\n",
    "        grid = self.obtener_grid(tipo_modelo)\n",
    "\n",
    "        claves = grid.keys()\n",
    "        valores = grid.values()\n",
    "\n",
    "\n",
    "        for combinacion in itertools.product(*valores):\n",
    "\n",
    "            parametros = dict(zip(claves, combinacion))\n",
    "\n",
    "            print(f\"Probando {tipo_modelo} con parámetros {parametros}\")\n",
    "\n",
    "            modelo = self.crear_modelo(tipo_modelo, parametros)\n",
    "\n",
    "            if tipo_modelo == \"xgb\":\n",
    "\n",
    "                modelo.fit(\n",
    "                    self.X_train,\n",
    "                    self.y_train,\n",
    "                    sample_weight=self.sample_weight,\n",
    "                    eval_set=[(self.X_val, self.y_val)],\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                modelo.fit(self.X_train, self.y_train)\n",
    "\n",
    "            predicciones = modelo.predict(self.X_val)\n",
    "\n",
    "            score = f1_score(self.y_val, predicciones, average=\"macro\")\n",
    "\n",
    "            print(\"Modelo validado: \", tipo_modelo)\n",
    "            print(\"F1 macro en set de validacion:\", score)\n",
    "            print(\"Parametros validados:\", parametros)\n",
    "\n",
    "\n",
    "            if score > self.mejor_score:\n",
    "\n",
    "                self.mejor_score = score\n",
    "                self.mejor_modelo = modelo\n",
    "                self.mejores_parametros = parametros\n",
    "                self.nombre_modelo= tipo_modelo\n",
    "            \n",
    "        \n",
    "    def evaluar_test(self):\n",
    "\n",
    "        print(\"Evaluación en Test\")\n",
    "        print(\"Mejor modelo tras validaciones: \",self.nombre_modelo)\n",
    "        print(\"Mejores parametros para dicho modelo: \",self.mejores_parametros)\n",
    "\n",
    "        pred_test = self.mejor_modelo.predict(self.X_test)\n",
    "\n",
    "        print(classification_report(self.y_test,pred_test,target_names=self.clases,digits=4))\n",
    "\n",
    "        print(\"Accuracy:\", accuracy_score(self.y_test, pred_test))\n",
    "        print(\"F1 Macro:\", f1_score(self.y_test, pred_test, average=\"macro\"))\n",
    "        print(\"Recall por clase:\", recall_score(self.y_test, pred_test, average=None))\n",
    "\n",
    "        matrizDeConfusion = confusion_matrix(self.y_test, pred_test)\n",
    "\n",
    "        print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d525a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando xgb con parámetros {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.9451831562140736\n",
      "Parametros validados: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05}\n",
      "Probando xgb con parámetros {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.9418769823596918\n",
      "Parametros validados: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1}\n",
      "Probando xgb con parámetros {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.9324256969142993\n",
      "Parametros validados: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Probando xgb con parámetros {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.9322443684093926\n",
      "Parametros validados: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Probando xgb con parámetros {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.9380731937840989\n",
      "Parametros validados: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05}\n",
      "Probando xgb con parámetros {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.9403529975034384\n",
      "Parametros validados: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1}\n",
      "Probando xgb con parámetros {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.9300593956850532\n",
      "Parametros validados: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Probando xgb con parámetros {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Modelo validado:  xgb\n",
      "F1 macro en set de validacion: 0.93021179191234\n",
      "Parametros validados: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Probando rf con parámetros {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}\n",
      "Modelo validado:  rf\n",
      "F1 macro en set de validacion: 0.9131577270980447\n",
      "Parametros validados: {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}\n",
      "Probando rf con parámetros {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 4}\n",
      "Modelo validado:  rf\n",
      "F1 macro en set de validacion: 0.9160220751114198\n",
      "Parametros validados: {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 4}\n",
      "Probando rf con parámetros {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 1}\n",
      "Modelo validado:  rf\n",
      "F1 macro en set de validacion: 0.920399046610102\n",
      "Parametros validados: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 1}\n",
      "Probando rf con parámetros {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4}\n",
      "Modelo validado:  rf\n",
      "F1 macro en set de validacion: 0.9195439079695551\n",
      "Parametros validados: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4}\n",
      "Probando rf con parámetros {'n_estimators': 400, 'max_depth': None, 'min_samples_leaf': 1}\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.6 MiB for an array with shape (1911456, 1) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\_utils.py\", line 109, in __call__\n    return self.func(**kwargs)\n           ~~~~~~~~~^^^^^^^^^^\n  File \"c:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 184, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n    tree._fit(\n    ~~~~~~~~~^\n        X,\n        ^^\n    ...<3 lines>...\n        missing_values_in_feature_mask=missing_values_in_feature_mask,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 306, in _fit\n    y_encoded = np.zeros(y.shape, dtype=int)\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 14.6 MiB for an array with shape (1911456, 1) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m busqueda = BusquedaHiperparametros(\n\u001b[32m      2\u001b[39m     X_train, y_train,\n\u001b[32m      3\u001b[39m     X_val, y_val,\n\u001b[32m      4\u001b[39m     X_test, y_test)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m modelo \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mxgb\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msvm\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mbusqueda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuscar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m busqueda.evaluar_test()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mBusquedaHiperparametros.buscar\u001b[39m\u001b[34m(self, tipo_modelo)\u001b[39m\n\u001b[32m    124\u001b[39m     modelo.fit(\n\u001b[32m    125\u001b[39m         \u001b[38;5;28mself\u001b[39m.X_train,\n\u001b[32m    126\u001b[39m         \u001b[38;5;28mself\u001b[39m.y_train,\n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m         verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    130\u001b[39m     )\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[43mmodelo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m predicciones = modelo.predict(\u001b[38;5;28mself\u001b[39m.X_val)\n\u001b[32m    137\u001b[39m score = f1_score(\u001b[38;5;28mself\u001b[39m.y_val, predicciones, average=\u001b[33m\"\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\john8\\OneDrive\\Desktop\\Proyecto Integrador\\.venv\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 14.6 MiB for an array with shape (1911456, 1) and data type int64"
     ]
    }
   ],
   "source": [
    "busqueda = BusquedaHiperparametros(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test)\n",
    "\n",
    "for modelo in [\"xgb\", \"rf\", \"svm\"]:\n",
    "    busqueda.buscar(modelo)\n",
    "    \n",
    "busqueda.evaluar_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6295a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
